# ============================================================
# ğŸ“„ íŒŒì¼ëª…: predict_and_advise.py
# ğŸ“ ìœ„ì¹˜: ai_modules/src/predict_and_advise.py
# ğŸ“˜ ëª©ì :
#   - ê²½ëŸ‰ LightCNN(64x64)ìœ¼ë¡œ ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ë¥˜ í›„,
#     ì„ íƒì ìœ¼ë¡œ LLMì„ í˜¸ì¶œí•´ ì„ì‚°ë¶€ ë³µìš© ê°€ëŠ¥ ì—¬ë¶€ ì•ˆë‚´ë¬¸ì„ ìƒì„±í•¨.
#
# ğŸ§ª ì‚¬ìš© ì˜ˆì‹œ:
#   # ì˜ˆì¸¡ë§Œ
#   python -m ai_modules.src.predict_and_advise \
#     --weights /path/best_model.pth \
#     --image   /path/sample.jpg \
#     --idx2label-json /path/matched_all.json \
#     --img-size 64
#
#   # ì˜ˆì¸¡ + LLM ìë¬¸
#   python -m ai_modules.src.predict_and_advise \
#     --weights /path/best_model.pth \
#     --image   /path/sample.jpg \
#     --idx2label-json /path/matched_all.json \
#     --img-size 64 --ask-llm --openai-model gpt-4o
#
# âœ… íŠ¹ì§•:
#   - ì²´í¬í¬ì¸íŠ¸ê°€ state_dict ë˜ëŠ” {"model_state_dict": ...} ëª¨ë‘ ì§€ì›ë¨.
#   - idx2label JSONì´ ì—†ìœ¼ë©´ ë¼ë²¨ ë¬¸ìì—´ ì—†ì´ ì¸ë±ìŠ¤ë§Œ ë°˜í™˜í•¨.
# ============================================================

from __future__ import annotations
import argparse, os
from typing import Dict, Any, Optional
from PIL import Image
import torch
from torchvision import transforms

from ai_modules.src.models.model_lightcnn import LightCNN
from ai_modules.src.utils.idx2label import load_idx2label_from_json, map_index
from ai_modules.src.services.pregnancy_advice import ask_pregnancy_safety

def _build_transform(img_size: int):
    return transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
    ])

def _load_model(weights: str, num_classes: int, device: torch.device) -> LightCNN:
    model = LightCNN(num_classes=num_classes).to(device)
    ckpt = torch.load(weights, map_location=device)
    state_dict = ckpt.get("model_state_dict", ckpt) if isinstance(ckpt, dict) else ckpt
    model.load_state_dict(state_dict)
    model.eval()
    return model

@torch.no_grad()
def run_once(
    weights: str,
    image: str,
    img_size: int = 64,
    idx2label_json: Optional[str] = None,
    num_classes: Optional[int] = None,
    ask_llm: bool = False,
    openai_model: Optional[str] = None,
) -> Dict[str, Any]:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tfm = _build_transform(img_size)

    # idx2label ë¡œë“œ(ì„ íƒ)
    idx2label = None
    if idx2label_json:
        try:
            idx2label = load_idx2label_from_json(idx2label_json)
        except Exception as e:
            print(f"[WARN] idx2label ë¡œë“œ ì‹¤íŒ¨: {e}")

    # í´ë˜ìŠ¤ ìˆ˜ ê²°ì •
    inferred_nc = num_classes or (len(idx2label) if idx2label else None)
    if inferred_nc is None:
        raise ValueError("num_classesë¥¼ ì§€ì •í•˜ê±°ë‚˜ idx2label_jsonì„ ì œê³µí•´ì•¼ í•¨.")

    # ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡ 
    model = _load_model(weights, inferred_nc, device)
    x = tfm(Image.open(image).convert("RGB")).unsqueeze(0).to(device)
    logits = model(x)[0]
    probs = torch.softmax(logits, dim=0)
    pred_idx = int(torch.argmax(probs).item())
    conf = float(probs[pred_idx].item())

    out: Dict[str, Any] = {
        "pred_index": pred_idx,
        "confidence": round(conf, 4),
    }

    if idx2label:
        out["pred_label"] = map_index(idx2label, pred_idx)

    # LLM ìë¬¸(ì„ íƒ)
    if ask_llm:
        if openai_model:
            os.environ["OPENAI_MODEL"] = openai_model
        pill_name = out.get("pred_label", f"Label-{pred_idx}")
        out["llm_advice"] = ask_pregnancy_safety(pill_name)

    return out

def main():
    ap = argparse.ArgumentParser(description="LightCNN ì˜ˆì¸¡ + ì„ì‚°ë¶€ ë³µìš© ìë¬¸(ì„ íƒ) í†µí•© ìŠ¤í¬ë¦½íŠ¸ì„.")
    ap.add_argument("--weights", required=True, help="ëª¨ë¸ ê°€ì¤‘ì¹˜(.pt)")
    ap.add_argument("--image",   required=True, help="ì¶”ë¡ í•  ì´ë¯¸ì§€ ê²½ë¡œ")
    ap.add_argument("--img-size", type=int, default=64, help="ì…ë ¥ í¬ê¸°(ê¸°ë³¸ 64)")
    ap.add_argument("--idx2label-json", type=str, default=None, help="ë¼ë²¨ ë§¤í•‘ JSON(ì„ íƒ)")
    ap.add_argument("--num-classes", type=int, default=None, help="í´ë˜ìŠ¤ ìˆ˜(ë¯¸ì§€ì • ì‹œ idx2label ê¸¸ì´)")

    ap.add_argument("--ask-llm", action="store_true", help="LLM ìë¬¸ ì‹¤í–‰")
    ap.add_argument("--openai-model", type=str, default=None, help="ì˜ˆ: gpt-4, gpt-4o, gpt-4o-mini")
    args = ap.parse_args()

    out = run_once(
        weights=args.weights,
        image=args.image,
        img_size=args.img_size,
        idx2label_json=args.idx2label_json,
        num_classes=args.num_classes,
        ask_llm=args.ask_llm,
        openai_model=args.openai_model,
    )
    print(out)

if __name__ == "__main__":
    main()
